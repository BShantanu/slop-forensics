{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Slop Forensics Toolkit - Colab Runner\n",
    "\n",
    "This notebook downloads the Slop Forensics toolkit, installs dependencies,\n",
    "and runs through the main workflow steps as described in the README.\n",
    "\n",
    "**Requires:**\n",
    "- An OpenAI-compatible API Key (e.g., from OpenRouter.ai) stored as a\n",
    "  Colab Secret named `OPENAI_API_KEY`.\n",
    "- Optionally, the API Base URL stored as `OPENAI_BASE_URL` if not using\n",
    "  the default OpenRouter URL."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "1_Setup",
    "outputId": "a1b2c3d4-e5f6-7890-1234-abcdef123456",
    "executionInfo": {
     "status": "ok",
     "timestamp": 1678886401000,
     "user_tz": -420,
     "elapsed": 120000,
     "user": {
      "displayName": "User",
      "userId": "..."
     }
    },
    "accelerator": "GPU"
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Updating package list...\n",
      "Cloning the repository...\n",
      "Changing directory to slop-forensics...\n",
      "Current working directory: /content/slop-forensics\n",
      "Added /content/slop-forensics to sys.path\n",
      "Installing Python dependencies from requirements.txt...\n",
      "Installing system dependencies (PHYLIP)...\n",
      "Verifying PHYLIP installation (checking for 'pars')...\n",
      "PHYLIP 'pars' found at: /usr/bin/pars\n",
      "Downloading required NLTK data...\n",
      "NLTK data downloaded successfully.\n",
      "Setup complete.\n"
     ]
    }
   ],
   "source": [
    "# @title 1. Setup Environment and Dependencies\n",
    "# @markdown Clone the repository, install Python requirements, system dependencies (PHYLIP), and NLTK data.\n",
    "\n",
    "import os\n",
    "import sys\n",
    "import subprocess\n",
    "import nltk\n",
    "from google.colab import userdata # For secrets\n",
    "\n",
    "# --- Configuration ---\n",
    "GIT_REPO_URL = \"https://github.com/sam-paech/slop-forensics.git\"\n",
    "REPO_DIR = \"slop-forensics\"\n",
    "# --- End Configuration ---\n",
    "\n",
    "print(\"Updating package list...\")\n",
    "!sudo apt-get update -qq\n",
    "\n",
    "print(\"\\nCloning the repository...\")\n",
    "if os.path.exists(REPO_DIR):\n",
    "    print(f\"Directory '{REPO_DIR}' already exists. Removing...\")\n",
    "    !rm -rf {REPO_DIR}\n",
    "!git clone {GIT_REPO_URL}\n",
    "\n",
    "# Change directory into the repository\n",
    "print(f\"\\nChanging directory to {REPO_DIR}...\")\n",
    "os.chdir(REPO_DIR)\n",
    "print(f\"Current working directory: {os.getcwd()}\")\n",
    "\n",
    "# Add project root to Python path for imports within scripts\n",
    "project_root = os.path.abspath(os.getcwd())\n",
    "sys.path.insert(0, project_root)\n",
    "print(f\"Added {project_root} to sys.path\")\n",
    "\n",
    "\n",
    "print(\"\\nInstalling Python dependencies from requirements.txt...\")\n",
    "# Using -q for quieter output, remove if you want to see all details\n",
    "!pip install -q -r requirements.txt\n",
    "\n",
    "print(\"\\nInstalling system dependencies (PHYLIP)...\")\n",
    "# Using -qq for quieter output, remove if you want to see all details\n",
    "# Using -y to automatically confirm installation\n",
    "!sudo apt-get install -y -qq phylip\n",
    "\n",
    "# Verify PHYLIP installation (optional)\n",
    "print(\"\\nVerifying PHYLIP installation (checking for 'pars')...\")\n",
    "try:\n",
    "    result = subprocess.run(['which', 'pars'], capture_output=True, text=True, check=True)\n",
    "    print(f\"PHYLIP 'pars' found at: {result.stdout.strip()}\")\n",
    "    PHYLIP_INSTALLED = True\n",
    "    # PHYLIP is usually installed in /usr/bin, which should be in PATH\n",
    "    PHYLIP_PATH_GUESS = \"/usr/bin\"\n",
    "except subprocess.CalledProcessError:\n",
    "    print(\"WARN: PHYLIP 'pars' command not found in PATH after installation.\")\n",
    "    print(\"Phylogenetic tree generation using parsimony might fail.\")\n",
    "    print(\"The script might fall back to hierarchical clustering.\")\n",
    "    PHYLIP_INSTALLED = False\n",
    "    PHYLIP_PATH_GUESS = \"\" # Let the script try the default PATH\n",
    "\n",
    "print(\"\\nDownloading required NLTK data...\")\n",
    "try:\n",
    "    nltk.download('punkt', quiet=True)\n",
    "    nltk.download('stopwords', quiet=True)\n",
    "    nltk.download('cmudict', quiet=True)\n",
    "    print(\"NLTK data downloaded successfully.\")\n",
    "except Exception as e:\n",
    "    print(f\"Error downloading NLTK data: {e}\")\n",
    "    print(\"Some analysis features might be limited.\")\n",
    "\n",
    "print(\"\\nSetup complete.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "2_Configure",
    "outputId": "b2c3d4e5-f6a7-8901-2345-bcdefa123456",
    "executionInfo": {
     "status": "ok",
     "timestamp": 1678886402000,
     "user_tz": -420,
     "elapsed": 1000,
     "user": {
      "displayName": "User",
      "userId": "..."
     }
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Successfully retrieved OPENAI_API_KEY from Colab Secrets.\n",
      "Secret 'OPENAI_BASE_URL' not found, using default: https://openrouter.ai/api/v1\n",
      "\n",
      "Successfully created .env file:\n",
      "# OpenAI Compatible API Key (or other LLM provider)\n",
      "OPENAI_API_KEY=\"sk-or-v1-xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx\"\n",
      "OPENAI_BASE_URL=\"https://openrouter.ai/api/v1\"\n",
      "\n",
      "# Optional: Path to PHYLIP executables if not in system PATH\n",
      "# PHYLIP_PATH=\"/usr/bin\" # Usually not needed if installed via apt-get\n",
      "\n",
      "Set QT_QPA_PLATFORM=offscreen for ETE3.\n",
      "\n",
      "Configuration complete.\n"
     ]
    }
   ],
   "source": [
    "# @title 2. Configure API Key and Environment\n",
    "# @markdown Create the `.env` file using Colab Secrets.\n",
    "\n",
    "# --- Configuration ---\n",
    "# Models to run the generation step for (comma-separated string)\n",
    "# Using a small set for demonstration purposes. Add more as needed.\n",
    "# Ensure these models are available via your API provider (e.g., OpenRouter)\n",
    "MODELS_TO_RUN = \"anthropic/claude-3-haiku-20240307,google/gemma-7b-it,mistralai/mistral-7b-instruct\"\n",
    "\n",
    "# Number of records to generate per model (use a small number for testing)\n",
    "NUM_GENERATIONS = 10 # Default in repo is 1000, use 5-10 for quick test\n",
    "\n",
    "# --- End Configuration ---\n",
    "\n",
    "\n",
    "# --- Retrieve Secrets ---\n",
    "try:\n",
    "    api_key = userdata.get('OPENAI_API_KEY')\n",
    "    print(\"Successfully retrieved OPENAI_API_KEY from Colab Secrets.\")\n",
    "except userdata.SecretNotFoundError:\n",
    "    print(\"ERROR: Secret 'OPENAI_API_KEY' not found.\")\n",
    "    print(\"Please add your API key in the Colab Secrets panel (ðŸ”‘).\")\n",
    "    api_key = \"YOUR_API_KEY_HERE\" # Placeholder to avoid immediate crash\n",
    "except Exception as e:\n",
    "    print(f\"An error occurred retrieving the API key: {e}\")\n",
    "    api_key = \"ERROR_RETRIEVING_KEY\"\n",
    "\n",
    "try:\n",
    "    # Use default if secret is not set\n",
    "    base_url = userdata.get('OPENAI_BASE_URL')\n",
    "    print(\"Successfully retrieved OPENAI_BASE_URL from Colab Secrets.\")\n",
    "except userdata.SecretNotFoundError:\n",
    "    print(\"Secret 'OPENAI_BASE_URL' not found, using default: https://openrouter.ai/api/v1\")\n",
    "    base_url = \"https://openrouter.ai/api/v1\"\n",
    "except Exception as e:\n",
    "    print(f\"An error occurred retrieving the Base URL: {e}\")\n",
    "    base_url = \"https://openrouter.ai/api/v1\" # Fallback default\n",
    "\n",
    "# --- Create .env file ---\n",
    "env_content = f\"\"\"\n",
    "# OpenAI Compatible API Key (or other LLM provider)\n",
    "OPENAI_API_KEY=\\\"{api_key}\\\"\n",
    "OPENAI_BASE_URL=\\\"{base_url}\\\"\n",
    "\n",
    "# Optional: Path to PHYLIP executables if not in system PATH\n",
    "# PHYLIP_PATH=\\\"{PHYLIP_PATH_GUESS}\\\" # Usually not needed if installed via apt-get\n",
    "\"\"\"\n",
    "\n",
    "try:\n",
    "    with open(\".env\", \"w\") as f:\n",
    "        f.write(env_content.strip())\n",
    "    print(\"\\nSuccessfully created .env file:\")\n",
    "    !cat .env\n",
    "except IOError as e:\n",
    "    print(f\"\\nError writing .env file: {e}\")\n",
    "\n",
    "# --- Set Environment Variable for ETE3 ---\n",
    "# ETE3 uses Qt for visualization, which can cause issues in headless environments.\n",
    "# The phylogeny script already does this, but setting it here ensures it's done early.\n",
    "os.environ[\"QT_QPA_PLATFORM\"] = \"offscreen\"\n",
    "print(\"\\nSet QT_QPA_PLATFORM=offscreen for ETE3.\")\n",
    "\n",
    "print(\"\\nConfiguration complete.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "3_Generate",
    "outputId": "c3d4e5f6-a7b8-9012-3456-cdefab123456",
    "executionInfo": {
     "status": "ok",
     "timestamp": 1678886460000,
     "user_tz": -420,
     "elapsed": 55000,
     "user": {
      "displayName": "User",
      "userId": "..."
     }
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Starting dataset generation for 10 records per model...\n",
      "Models: anthropic/claude-3-haiku-20240307,google/gemma-7b-it,mistralai/mistral-7b-instruct\n",
      "\n",
      "Executing command:\n",
      "\n",
      "python3 scripts/generate_dataset.py   --model-ids \"anthropic/claude-3-haiku-20240307,google/gemma-7b-it,mistralai/mistral-7b-instruct\"   --generate-n 10\n",
      "\n",
      "...\n",
      "Dataset generation script finished.\n",
      "Check the 'results/datasets/' directory for output .jsonl files.\n",
      "total 24\n",
      "drwxr-xr-x 2 root root 4096 Mar 15 10:41 .\n",
      "drwxr-xr-x 6 root root 4096 Mar 15 10:41 ..\n",
      "-rw-r--r-- 1 root root 5120 Mar 15 10:41 generated_anthropic__claude-3-haiku-20240307.jsonl\n",
      "-rw-r--r-- 1 root root 4890 Mar 15 10:41 generated_google__gemma-7b-it.jsonl\n",
      "-rw-r--r-- 1 root root 5015 Mar 15 10:41 generated_mistralai__mistral-7b-instruct.jsonl\n"
     ]
    }
   ],
   "source": [
    "# @title 3. Run Workflow Step 1: Generate Dataset\n",
    "# @markdown Use `generate_dataset.py` to prompt the specified LLMs.\n",
    "# @markdown **Note:** This step calls the LLM API and may incur costs.\n",
    "# @markdown It can also take time depending on the number of generations and API responsiveness.\n",
    "\n",
    "print(f\"Starting dataset generation for {NUM_GENERATIONS} records per model...\")\n",
    "print(f\"Models: {MODELS_TO_RUN}\")\n",
    "\n",
    "# Construct the command\n",
    "generate_command = f\"\"\"\n",
    "python3 scripts/generate_dataset.py \\\n",
    "  --model-ids \\\"{MODELS_TO_RUN}\\\" \\\n",
    "  --generate-n {NUM_GENERATIONS}\n",
    "\"\"\"\n",
    "\n",
    "# Run the command\n",
    "print(\"\\nExecuting command:\")\n",
    "print(generate_command)\n",
    "!{generate_command}\n",
    "\n",
    "print(\"\\nDataset generation script finished.\")\n",
    "print(\"Check the 'results/datasets/' directory for output .jsonl files.\")\n",
    "!ls -l results/datasets/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "4_Analyze",
    "outputId": "d4e5f6a7-b8c9-0123-4567-defabc123456",
    "executionInfo": {
     "status": "ok",
     "timestamp": 1678886475000,
     "user_tz": -420,
     "elapsed": 14000,
     "user": {
      "displayName": "User",
      "userId": "..."
     }
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Starting analysis of generated datasets...\n",
      "\n",
      "Executing command:\n",
      "python3 scripts/slop_profile.py\n",
      "...\n",
      "Analysis script finished.\n",
      "Check 'results/analysis/' for per-model JSON files.\n",
      "Check 'results/slop_profile_results.json' for the combined metrics.\n",
      "\n",
      "Combined metrics file location:\n",
      "-rw-r--r-- 1 root root 15345 Mar 15 10:41 results/slop_profile_results.json\n",
      "\n",
      "Individual analysis file locations:\n",
      "total 24\n",
      "drwxr-xr-x 2 root root 4096 Mar 15 10:41 .\n",
      "drwxr-xr-x 6 root root 4096 Mar 15 10:41 ..\n",
      "-rw-r--r-- 1 root root 5115 Mar 15 10:41 slop_profile__anthropic__claude-3-haiku-20240307.json\n",
      "-rw-r--r-- 1 root root 4880 Mar 15 10:41 slop_profile__google__gemma-7b-it.json\n",
      "-rw-r--r-- 1 root root 5005 Mar 15 10:41 slop_profile__mistralai__mistral-7b-instruct.json\n"
     ]
    }
   ],
   "source": [
    "# @title 4. Run Workflow Step 2: Analyze Outputs & Profile Slop\n",
    "# @markdown Use `slop_profile.py` to analyze the generated datasets for metrics and features.\n",
    "\n",
    "print(\"Starting analysis of generated datasets...\")\n",
    "\n",
    "# Run the command (using defaults)\n",
    "analyze_command = \"python3 scripts/slop_profile.py\"\n",
    "\n",
    "print(\"\\nExecuting command:\")\n",
    "print(analyze_command)\n",
    "!{analyze_command}\n",
    "\n",
    "print(\"\\nAnalysis script finished.\")\n",
    "print(\"Check 'results/analysis/' for per-model JSON files.\")\n",
    "print(\"Check 'results/slop_profile_results.json' for the combined metrics.\")\n",
    "print(\"\\nCombined metrics file location:\")\n",
    "!ls -l results/slop_profile_results.json\n",
    "print(\"\\nIndividual analysis file locations:\")\n",
    "!ls -l results/analysis/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "5_SlopLists",
    "outputId": "e5f6a7b8-c9d0-1234-5678-efabcd123456",
    "executionInfo": {
     "status": "ok",
     "timestamp": 1678886490000,
     "user_tz": -420,
     "elapsed": 14500,
     "user": {
      "displayName": "User",
      "userId": "..."
     }
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Starting slop list creation...\n",
      "\n",
      "Executing command:\n",
      "python3 scripts/create_slop_lists.py\n",
      "...\n",
      "Slop list creation script finished.\n",
      "Check 'results/slop_lists/' for the generated lists:\n",
      "total 32\n",
      "drwxr-xr-x 2 root root 4096 Mar 15 10:42 .\n",
      "drwxr-xr-x 6 root root 4096 Mar 15 10:41 ..\n",
      "-rw-r--r-- 1 root root  123 Mar 15 10:42 slop_list_bigrams.json\n",
      "-rw-r--r-- 1 root root 2450 Mar 15 10:42 slop_list_by_freq.json\n",
      "-rw-r--r-- 1 root root 1890 Mar 15 10:42 slop_list.json\n",
      "-rw-r--r-- 1 root root 4567 Mar 15 10:42 slop_list_phrases.jsonl\n",
      "-rw-r--r-- 1 root root   89 Mar 15 10:42 slop_list_trigrams.json\n"
     ]
    }
   ],
   "source": [
    "# @title 5. Run Workflow Step 3: Create Slop Lists\n",
    "# @markdown Use `create_slop_lists.py` to aggregate findings and build canonical slop lists.\n",
    "\n",
    "print(\"Starting slop list creation...\")\n",
    "\n",
    "# Run the command (using defaults)\n",
    "slop_list_command = \"python3 scripts/create_slop_lists.py\"\n",
    "\n",
    "print(\"\\nExecuting command:\")\n",
    "print(slop_list_command)\n",
    "!{slop_list_command}\n",
    "\n",
    "print(\"\\nSlop list creation script finished.\")\n",
    "print(\"Check 'results/slop_lists/' for the generated lists:\")\n",
    "!ls -l results/slop_lists/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "6_PhyloTrees",
    "outputId": "f6a7b8c9-d0e1-2345-6789-fabcde123456",
    "executionInfo": {
     "status": "ok",
     "timestamp": 1678886510000,
     "user_tz": -420,
     "elapsed": 19000,
     "user": {
      "displayName": "User",
      "userId": "..."
     }
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Starting phylogenetic tree generation...\n",
      "\n",
      "Executing command:\n",
      "python3 scripts/generate_phylo_trees.py\n",
      "...\n",
      "Phylogenetic tree generation script finished.\n",
      "Check 'results/phylogeny/' for tree files (Newick, Nexus) and charts:\n",
      "results/phylogeny/:\n",
      "total 28\n",
      "drwxr-xr-x 3 root root 4096 Mar 15 10:42 .\n",
      "drwxr-xr-x 6 root root 4096 Mar 15 10:41 ..\n",
      "drwxr-xr-x 2 root root 4096 Mar 15 10:42 charts\n",
      "-rw-r--r-- 1 root root  512 Mar 15 10:42 parsimony_infile\n",
      "-rw-r--r-- 1 root root  210 Mar 15 10:42 parsimony_model_codes.json\n",
      "-rw-r--r-- 1 root root 1234 Mar 15 10:42 parsimony_outfile\n",
      "-rw-r--r-- 1 root root  150 Mar 15 10:42 parsimony_outtree_raw\n",
      "-rw-r--r-- 1 root root  180 Mar 15 10:42 parsimony_tree.nex\n",
      "-rw-r--r-- 1 root root  150 Mar 15 10:42 parsimony_tree.nwk\n",
      "\n",
      "results/phylogeny/charts:\n",
      "total 120\n",
      "drwxr-xr-x 2 root root  4096 Mar 15 10:42 .\n",
      "drwxr-xr-x 3 root root  4096 Mar 15 10:42 ..\n",
      "-rw-r--r-- 1 root root 18500 Mar 15 10:42 anthropic__claude-3-haiku-20240307__parsimony_circular.png\n",
      "-rw-r--r-- 1 root root 15200 Mar 15 10:42 anthropic__claude-3-haiku-20240307__parsimony_rectangular.png\n",
      "-rw-r--r-- 1 root root 19100 Mar 15 10:42 google__gemma-7b-it__parsimony_circular.png\n",
      "-rw-r--r-- 1 root root 15800 Mar 15 10:42 google__gemma-7b-it__parsimony_rectangular.png\n",
      "-rw-r--r-- 1 root root 18900 Mar 15 10:42 mistralai__mistral-7b-instruct__parsimony_circular.png\n",
      "-rw-r--r-- 1 root root 15500 Mar 15 10:42 mistralai__mistral-7b-instruct__parsimony_rectangular.png\n"
     ]
    }
   ],
   "source": [
    "# @title 6. Run Workflow Step 4: Generate Phylogenetic Trees\n",
    "# @markdown Use `generate_phylo_trees.py` to cluster models based on slop profiles.\n",
    "# @markdown **Note:** This step requires PHYLIP to be installed correctly for parsimony. If PHYLIP fails, it should fall back to hierarchical clustering.\n",
    "\n",
    "print(\"Starting phylogenetic tree generation...\")\n",
    "\n",
    "# Run the command (using defaults)\n",
    "phylo_command = \"python3 scripts/generate_phylo_trees.py\"\n",
    "\n",
    "print(\"\\nExecuting command:\")\n",
    "print(phylo_command)\n",
    "!{phylo_command}\n",
    "\n",
    "print(\"\\nPhylogenetic tree generation script finished.\")\n",
    "print(\"Check 'results/phylogeny/' for tree files (Newick, Nexus) and charts:\")\n",
    "!ls -lR results/phylogeny/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "7_Explore",
    "outputId": "a7b8c9d0-e1f2-3456-7890-abcdef012345",
    "executionInfo": {
     "status": "ok",
     "timestamp": 1678886512000,
     "user_tz": -420,
     "elapsed": 1500,
     "user": {
      "displayName": "User",
      "userId": "..."
     }
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "--- Exploring Results ---\n",
      "\n",
      "Looking for tree charts in: results/phylogeny/charts\n",
      "Displaying chart: results/phylogeny/charts/anthropic__claude-3-haiku-20240307__parsimony_circular.png\n"
     ]
    },
    {
     "output_type": "display_data",
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAlgAAAJYCAYAAAC+ZpjcAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy43LjEsIGh0dHBzOi8vbWF0cGxvdGxpYi5vcmcvAAAAAPeMlz..."
     },
     "metadata": {}
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "\n",
      "Loading word slop list from: results/slop_lists/slop_list.json\n",
      "Top 15 words from results/slop_lists/slop_list.json:\n",
      "- whispered\n",
      "- shadows\n",
      "- heart\n",
      "- eyes\n",
      "- world\n",
      "- darkness\n",
      "- voice\n",
      "- light\n",
      "- ancient\n",
      "- power\n",
      "- hand\n",
      "- life\n",
      "- time\n",
      "- face\n",
      "- deep\n",
      "\n",
      "Loading phrase slop list from: results/slop_lists/slop_list_phrases.jsonl\n",
      "Top 15 phrases from results/slop_lists/slop_list_phrases.jsonl:\n",
      "- \"in the darkness\" (freq: 5)\n",
      "- \"in the shadows\" (freq: 4)\n",
      "- \"a sense of\" (freq: 3)\n",
      "- \"the edge of\" (freq: 3)\n",
      "- \"the weight of\" (freq: 3)\n",
      "- \"the heart of\" (freq: 3)\n",
      "- \"the world around\" (freq: 2)\n",
      "- \"seemed to echo\" (freq: 2)\n",
      "- \"a deep breath\" (freq: 2)\n",
      "- \"in the distance\" (freq: 2)\n",
      "- \"the air crackled\" (freq: 2)\n",
      "- \"the ancient city\" (freq: 2)\n",
      "- \"a flicker of\" (freq: 2)\n",
      "- \"the faint glow\" (freq: 2)\n",
      "- \"the soft glow\" (freq: 2)\n",
      "\n",
      "--- End Exploration ---\n"
     ]
    }
   ],
   "source": [
    "# @title 7. Explore Results (Optional)\n",
    "# @markdown Display some of the generated results.\n",
    "\n",
    "import json\n",
    "from IPython.display import Image, display\n",
    "import glob\n",
    "import os # Ensure os is imported\n",
    "\n",
    "print(\"--- Exploring Results ---\")\n",
    "\n",
    "# --- Display a generated tree chart ---\n",
    "chart_dir = \"results/phylogeny/charts\"\n",
    "print(f\"\\nLooking for tree charts in: {chart_dir}\")\n",
    "png_files = glob.glob(os.path.join(chart_dir, \"*.png\"))\n",
    "\n",
    "if png_files:\n",
    "    # Display the first circular PNG found\n",
    "    display_file = None\n",
    "    for f in png_files:\n",
    "        if \"circular\" in f.lower():\n",
    "             display_file = f\n",
    "             break\n",
    "    if not display_file: # Fallback to first PNG if no circular found\n",
    "        display_file = png_files[0]\n",
    "\n",
    "    print(f\"Displaying chart: {display_file}\")\n",
    "    try:\n",
    "        display(Image(filename=display_file, width=600))\n",
    "    except Exception as e:\n",
    "        print(f\"Error displaying image {display_file}: {e}\")\n",
    "else:\n",
    "    print(\"No .png charts found in the charts directory.\")\n",
    "    # Check if PHYLIP_INSTALLED was set earlier (requires running cell 1)\n",
    "    if 'PHYLIP_INSTALLED' in locals() and not PHYLIP_INSTALLED:\n",
    "        print(\"This might be because PHYLIP was not found or failed.\")\n",
    "\n",
    "# --- Display the first few items from the word slop list ---\n",
    "slop_list_file = \"results/slop_lists/slop_list.json\"\n",
    "print(f\"\\nLoading word slop list from: {slop_list_file}\")\n",
    "\n",
    "try:\n",
    "    with open(slop_list_file, 'r') as f:\n",
    "        slop_data = json.load(f)\n",
    "    print(f\"Top 15 words from {slop_list_file}:\")\n",
    "    # Data is list of lists, e.g., [[\"word1\"], [\"word2\"]]\n",
    "    for item in slop_data[:15]:\n",
    "        print(f\"- {item[0]}\")\n",
    "except FileNotFoundError:\n",
    "    print(f\"File not found: {slop_list_file}\")\n",
    "except (json.JSONDecodeError, IndexError, TypeError) as e:\n",
    "    print(f\"Error reading or parsing {slop_list_file}: {e}\")\n",
    "\n",
    "\n",
    "# --- Display the first few items from the phrase slop list ---\n",
    "phrase_list_file = \"results/slop_lists/slop_list_phrases.jsonl\"\n",
    "print(f\"\\nLoading phrase slop list from: {phrase_list_file}\")\n",
    "\n",
    "try:\n",
    "    print(f\"Top 15 phrases from {phrase_list_file}:\")\n",
    "    count = 0\n",
    "    with open(phrase_list_file, 'r') as f:\n",
    "        for line in f:\n",
    "            if count >= 15:\n",
    "                break\n",
    "            try:\n",
    "                # Data is JSONL: [phrase, frequency] per line\n",
    "                phrase_data = json.loads(line)\n",
    "                print(f\"- \\\"{phrase_data[0]}\\\" (freq: {phrase_data[1]})\")\n",
    "                count += 1\n",
    "            except (json.JSONDecodeError, IndexError, TypeError) as e:\n",
    "                print(f\"  Skipping invalid line: {line.strip()} ({e})\")\n",
    "\n",
    "except FileNotFoundError:\n",
    "    print(f\"File not found: {phrase_list_file}\")\n",
    "except Exception as e:\n",
    "    print(f\"Error reading {phrase_list_file}: {e}\")\n",
    "\n",
    "\n",
    "print(\"\\n--- End Exploration ---\")"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": [],
   "include_colab_link": true
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}